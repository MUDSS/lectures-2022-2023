{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EEG feeling emotions\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1uHlS2GPhqjeEn1hAN_8pgxZpO9LQr5Nw?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "**Author:** Lifeng Qiu Lin\n"
      ],
      "metadata": {
        "id": "qBB2HMXRyQ6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment\n",
        "---\n",
        "Before hands on, get the **tools** 🧰 ready!"
      ],
      "metadata": {
        "id": "5QZwaRIpvcUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Import!"
      ],
      "metadata": {
        "id": "w8oz_eK6LA2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To import the tools (libraries) we need, run the following command."
      ],
      "metadata": {
        "id": "jiVL2Z_CLLTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Import libraries\n",
        "import torch, pandas, numpy, os, requests, zipfile, io, matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ],
      "metadata": {
        "id": "E1IPdc8nw4m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Turn on the **GPU**!"
      ],
      "metadata": {
        "id": "RuTrZ1ajGDU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the GPU (which makes code run faster), in the top left corner:\n",
        "- Click on *Edit*\n",
        "- Click on *Notebook settings*\n",
        "- From the drop down menu in *Hardware accelerator*\n",
        "- Select **GPU**\n",
        "- Save"
      ],
      "metadata": {
        "id": "1nVlSn6rGkiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ready? Check whether GPU is ready by running the following code. The output should be `Using cuda.`, via which GPU is used."
      ],
      "metadata": {
        "id": "iyXkhV8SKCw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [SHIFT + ENTER = RUN] Use GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device}.\")"
      ],
      "metadata": {
        "id": "AxQ_2lZbKsHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Locate\n"
      ],
      "metadata": {
        "id": "pASoea3LRrRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find a place to play around, let's create a folder called `EEG` and we build everything inside it. The result should be `/content/EEG folder`."
      ],
      "metadata": {
        "id": "Z2LSmcU5R-5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Create and get to `EEG` folder\n",
        "! mkdir -p /content/EEG\n",
        "%cd /content/EEG/\n"
      ],
      "metadata": {
        "id": "mQHnLP89SuRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data\n",
        "---\n",
        "Bring up the data✨, and let's see what it is made of!"
      ],
      "metadata": {
        "id": "iDl2E8m5Mu7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Download the data\n",
        "The result data stored in `/content/EEG/data/emotions.csv`."
      ],
      "metadata": {
        "id": "dzfx7qZJOXEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Download the eeg data\n",
        "! mkdir -p ./data\n",
        "! wget -q -O ./data/emotions.csv https://github.com/UOMDSS/workshops-2022-2023/raw/main/semester-1/Week-7-EEG-Feeling-Emotions-Logistic-Regression/data/emotions.csv\n",
        "! ls\n"
      ],
      "metadata": {
        "id": "hErG9ofbOs6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Read data\n",
        "Now that we have the data in a folder, we read it into our notebook environment. *The cells that you are working right now is in a thingy called \"notebook\".*"
      ],
      "metadata": {
        "id": "-Y--vMMpv_b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Read csv file\n",
        "data = pandas.read_csv(\"./data/emotions.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "SHUaVQOhDaj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see *mean*, some omitted columns, *fft*, *label*.\n",
        "This notebook shallowly explores the data, to better understand what is meant with each row and column, refer to the dataset.\n",
        "For example, the \"a\" and \"b\" in the end refers to whether the source of data is from person \"a\" or person \"b\".\n",
        "\n"
      ],
      "metadata": {
        "id": "2auT015Wg1T6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Understand data\n",
        "What is inside of this dataset? Dimensions? Type? What data can be useful?"
      ],
      "metadata": {
        "id": "P7evVYCxWgZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Print data about the data\n",
        "print(data.shape)\n",
        "print(data.columns)\n",
        "# for (i, col) in enumerate(data.columns):\n",
        "#   print(i, col)\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "EJlwvd5XXPFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ***Side notes***: fft stands for Fast Fourier Transform. This data enables us to represent a kind of *wave* graphs (time domain signals i.e. time vs amplitude) to another kind of *wave* graphs (frequency vs amplitude)。\n",
        "> The main point here is that **we can visualize that!**"
      ],
      "metadata": {
        "id": "uW4RQQUVYzq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Visualise data\n",
        "FFT columns represents elaborated signals, therefore, let's plot that brain signal as a graph."
      ],
      "metadata": {
        "id": "hmO37TnQeQ7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] [Tweakable] Extract fft data\n",
        "# ranges is tweakable\n",
        "start = 0 #@param {type:\"integer\"}\n",
        "end = 749 #@param {type:\"integer\"}\n",
        "ranges = [(f\"fft_{start}_a\", f\"fft_{end}_a\"), (\"label\", \"label\")]\n",
        "fft_data = pandas.concat([data.loc[:, i:j] for i, j in ranges], axis = 1) [data[\"label\"] != \"NEUTRAL\"].reset_index()\n",
        "fft_data"
      ],
      "metadata": {
        "id": "5j2KWz1te1GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the data size has been reduced to:\n",
        "- 1416 rows\n",
        "- 752 columns\n",
        "Why?"
      ],
      "metadata": {
        "id": "DjrYpe9-iU-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] [Tweakable] Plot fft brain signals\n",
        "# moment (row) is tweakable\n",
        "moment = 0 #@param {type:\"integer\"}\n",
        "fft_data.iloc[moment, 1:-1].plot(figsize=(20, 15), label=\"Fast Fourier Transform at 1s interval\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "-7GMh5bqivDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Brain signals over time\n",
        "fig = plt.figure(figsize=(25, 15))\n",
        "for i in range(0, 6):\n",
        "    plt.subplot(3, 2, i+1)\n",
        "    plt.plot(fft_data.iloc[i, 1:-1])\n",
        "    plt.title(\"Fast Fourier Transform on \" + fft_data.loc[i, \"label\"] + \" emotion\")"
      ],
      "metadata": {
        "id": "aPSBwFnpjkl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By eye, how would you say the differences between positive and negative brain signals?"
      ],
      "metadata": {
        "id": "ZnRGiNQAzZAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create model\n",
        "---\n",
        "Now it is time to write the **logistic regression** model ​⚒️!\n"
      ],
      "metadata": {
        "id": "rsgiIJOpzj8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ***Side notes***: we can if we want, write the step-by-step code of the model. But most of the times, we tend to use a *frameworks* (code), a prepared codebase that already has the skeleton of model. They are handy and easy to use.  \n",
        "> This notebook uses [**PyTorch**](https://pytorch.org/), a framework like this"
      ],
      "metadata": {
        "id": "tADhg3cbKh0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Dataset class\n",
        "Imagine the datasets as spare data which could come in any form, how can PyTorch handle each case?  \n",
        "The answer is that it **doesn't** handle, we as users are the ones responsible to moderate the data according to PyTorch **dataset interface**.  \n",
        "The following code is out of scope of this workshop. Just run it and should be fine, although you can have a look if interested."
      ],
      "metadata": {
        "id": "C6a2MZqiKbiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Define emotion dataset in PyTorch\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, df, transform=None, target_transform=None):\n",
        "        self.data = df\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data.iloc[index, :-1].values.astype(numpy.float64)\n",
        "        y = self.data.iloc[index, -1]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        if self.target_transform:\n",
        "            y = self.target_transform(y)\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "0uM2ynKIORAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Model class\n",
        "We aim to predict the emotion with a **logistic regression**, don't we?  \n",
        "Luckily, PyTorch is able to help you to write this model incredibly fast."
      ],
      "metadata": {
        "id": "nl695txCQ5zQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ***Side notes***:   \n",
        "  - `torch.nn.Linear(x, y)` maps `x` to `y` in a regression line.  \n",
        "  - `torch.sigmoid(x)` computes the value of x after applying sigmoid function\n"
      ],
      "metadata": {
        "id": "sYQ2YzSYRc0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Build Logistic Regression model\n",
        "class EmotionLogisticRegressionModel(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(EmotionLogisticRegressionModel, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_size, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "OCVpHLrrSkIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train model\n",
        "---\n",
        "The most intense part (for computers) comes now! We train 🏋 the model."
      ],
      "metadata": {
        "id": "oYbO2YqyT5_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Hyperparameters\n",
        "Different from the \"parameters\" which is obtained after training, \"hyperparameters\" are values that we humans choose to affect the model globally.  \n",
        "For example, choosing `cuda`, `GPU` as our hardware resource you can consider it as a kind of \"hyperparameter\"."
      ],
      "metadata": {
        "id": "YC7YFUYvU6kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] [Tweakable] Choose hyperparameters\n",
        "fft_start = 0 #@param {type:\"integer\"}\n",
        "fft_end = 20 #@param {type:\"integer\"}\n",
        "ranges = [(f\"fft_{fft_start}_a\", f\"fft_{fft_end}_a\"), (f\"fft_{fft_start}_b\", f\"fft_{fft_end}_b\"), (\"label\", \"label\")]\n",
        "train_proportion = 0.8 #@param {type:\"slider\", min: 0, max: 1, step: 0.05}\n",
        "batch_size = 64 #@param {type:\"integer\"}\n",
        "learning_rate = 0.01 #@param {type:\"number\"}\n",
        "epochs = 50 #@param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "dC6wZ5KQV6Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Create train and test cycles\n",
        "One last thing before training the model, is to wrap all the train cycle and test cycle as a \"function\" (function is just a block of code, callable with the name of the function). This gives us more concise and readable code.  \n",
        "You don't need to fully understand what is going on inside, as it has some complex concepts. But feel free to ask if you want to know it."
      ],
      "metadata": {
        "id": "TzZQV8ggjDk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Create train cycle\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ],
      "metadata": {
        "id": "_OLoj-Zri2QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Create test cycle\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X,y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: Accuracy: {100*(correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\\n\")\n"
      ],
      "metadata": {
        "id": "s7be4XErkHqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Train\n",
        "Finally! The following cell initialises the model and trains the model. Learning the data may take some time, please be patient. Same, some functions are specific to PyTorch, you don't need to fully understand them. Have a guess, what do they mean?"
      ],
      "metadata": {
        "id": "gSE1hDkZkVdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Initialise\n",
        "# Create dataset\n",
        "data = pandas.read_csv(\"./data/emotions.csv\")\n",
        "data = pandas.concat([data.loc[:, i:j] for i, j in ranges], axis=1)[data[\"label\"] != \"NEUTRAL\"].reset_index()\n",
        "input_size = data.shape[1] - 1\n",
        "output_size = 1\n",
        "dataset = EmotionDataset(data, transform=lambda x: torch.from_numpy(x).float(), target_transform=lambda x: torch.tensor([1]).float() if x == \"POSITIVE\" else torch.tensor([0]).float())\n",
        "train_size = int(train_proportion * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create model\n",
        "model = EmotionLogisticRegressionModel(input_size, output_size).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "7gMmF5UykvUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Train model!\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_loader, model, loss_fn, optimizer)\n",
        "    test(test_loader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "AoTbDvrjl5Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Test model\n",
        "---\n",
        "Finished! Now we can try this model out!  \n",
        "Choose one intance of the data, and then the model will predict it. Does the prediction match with the actual emotion?"
      ],
      "metadata": {
        "id": "X0ZqaJUJbPrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Use model!\n",
        "# From 0 to 1415\n",
        "choosed_data_index = 0 #@param {type:\"integer\"}\n",
        "choosed_data = data.iloc[choosed_data_index, :-1]\n",
        "prediction = model(torch.tensor(choosed_data.values.astype(numpy.float32)))\n",
        "print(f\"\"\"\n",
        "      Model's prediction: {'POSITIVE' if prediction[0] == 1 else 'NEGATIVE'}\n",
        "      Actual emotion: {data.iloc[choosed_data_index, -1]}\n",
        "      \"\"\")\n",
        "\n",
        "fft_data.iloc[choosed_data_index, 1:-1].plot(figsize=(20, 15), label=\"Fast Fourier Transform\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "oumV-NsMbhvX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}